<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"right","display":"hide","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    fancybox: false,
    mediumzoom: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="隐马尔科夫模型(Hidden Markov Model, 以下简称HMM), 是比较经典的机器学习模型了. 它在自然语言处理, 模式识别等领域得到广泛的应用.  当然, 随着目前深度学习的崛起, HMM的地位有所下降. 但是作为一个经典的模型, 学习HMM的模型和对应算法, 对我们解决问题建模的能力提高以及算法思路的拓展还是很好的.">
<meta name="keywords" content="EM算法,自然语言处理,HMM">
<meta property="og:type" content="article">
<meta property="og:title" content="隐马尔科夫模型HMM">
<meta property="og:url" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/index.html">
<meta property="og:site_name" content="阿枂蛋糕店">
<meta property="og:description" content="隐马尔科夫模型(Hidden Markov Model, 以下简称HMM), 是比较经典的机器学习模型了. 它在自然语言处理, 模式识别等领域得到广泛的应用.  当然, 随着目前深度学习的崛起, HMM的地位有所下降. 但是作为一个经典的模型, 学习HMM的模型和对应算法, 对我们解决问题建模的能力提高以及算法思路的拓展还是很好的.">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/fig_0.png">
<meta property="og:image" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/fig_1.png">
<meta property="og:image" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/fig_2.png">
<meta property="og:image" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/fig_2.png">
<meta property="og:updated_time" content="2020-10-10T15:04:33.156Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="隐马尔科夫模型HMM">
<meta name="twitter:description" content="隐马尔科夫模型(Hidden Markov Model, 以下简称HMM), 是比较经典的机器学习模型了. 它在自然语言处理, 模式识别等领域得到广泛的应用.  当然, 随着目前深度学习的崛起, HMM的地位有所下降. 但是作为一个经典的模型, 学习HMM的模型和对应算法, 对我们解决问题建模的能力提高以及算法思路的拓展还是很好的.">
<meta name="twitter:image" content="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/fig_0.png">





  
  
  <link rel="canonical" href="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>隐马尔科夫模型HMM | 阿枂蛋糕店</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">阿枂蛋糕店</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">在下月小白</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://smileshy777.github.io/2020/08/16/自然语言处理/隐马尔科夫模型HMM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="月小白">
      <meta itemprop="description" content="这是一家有爱的小店">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="阿枂蛋糕店">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">隐马尔科夫模型HMM

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-08-16 22:36:15" itemprop="dateCreated datePublished" datetime="2020-08-16T22:36:15+08:00">2020-08-16</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-10-10 23:04:33" itemprop="dateModified" datetime="2020-10-10T23:04:33+08:00">2020-10-10</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/自然语言处理/" itemprop="url" rel="index"><span itemprop="name">自然语言处理</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>隐马尔科夫模型(Hidden Markov Model, 以下简称HMM), 是比较经典的机器学习模型了. 它在自然语言处理, 模式识别等领域得到广泛的应用. </p>
<p>当然, 随着目前深度学习的崛起, HMM的地位有所下降. 但是作为一个经典的模型, 学习HMM的模型和对应算法, 对我们解决问题建模的能力提高以及算法思路的拓展还是很好的.</p>
<a id="more"></a>
<h1 id="HMM介绍"><a href="#HMM介绍" class="headerlink" title="HMM介绍"></a>HMM介绍</h1><p>首先看看什么样的问题解决可以用HMM模型, 可以使用HMM模型的问题一般有如下两个特征:</p>
<p>​    <strong>*</strong> 问题是<strong>基于序列</strong>的, 比如时间序列, 语言序列.</p>
<p>​    <strong>*</strong> 问题中有<strong>两类数据</strong>, 一类序列数据是可以观测到的, 即<strong>观测序列</strong>; 而另一类数据是不能观察到的, 即隐藏状态序列, 简称<strong>状态序列</strong>, 这也是模型名称中”隐”的由来.</p>
<p>一般来说, HMM经常用于解决<strong>序列标注问题(Sequence Labeling Problem)</strong>.</p>
<p><img src="fig_0.png" alt="fig"></p>
<p>如上图, 给到一个可观测序列$X$, 推断出隐藏序列$Y$. 具体说来, 比如要处理词性标注(POS tagging)问题, 即给出一段语句, 对语句中的各个词汇标注词性(如动词, 名词等). 那如果让HMM来做, 是如何处理这样的问题的呢?</p>
<p><img src="fig_1.png" alt="fig"></p>
<p>可以有这样的一个假设, 当我们在说一句话的时候, 我们第一步是通过语法规则, 生成一个词性序列, 然后第二步是基于这个词性序列与词典, 生成句子.</p>
<p>HMM本身的模型结构是一个有向图, 隐藏节点之间具有马尔可夫性, 即当前状态节点仅依赖于上一个节点, 同时当前可观测节点仅依赖于当前状态节点.</p>
<p>那么在这个模型结构之下, 整个过程(生成状态序列, 生成可观测序列)的联合概率计算方式如下图:</p>
<p><img src="fig_2.png" alt="fig"></p>
<p>联合概率的计算主要由两部分组成, 状态序列之间转移的部分称为转移概率(Transition probability), 从状态序列到观察序列的部分称为发射概率(Emission probability). 可以对应到两个参数矩阵, 马尔科夫链的状态转移矩阵$A$, 观察序列的生成(发射)矩阵$B$.</p>
<p><img src="fig_2.png" alt="fig"></p>
<p>到了这里, 大概知道HMM长什么样了, 同时也知道可以用来处理哪一类的问题. </p>
<p>假设模型参数为$\lambda=\{A,B\}$, 初始分布算作$A_{start}$, 观察序列为$O=\{o_1,o_2,\dots o_n\}$.</p>
<p>现在有了下面几个问题:</p>
<p>​    <strong>*</strong> 估计观察序列概率. 在已知模型参数$\lambda$和观察序列$O$的情况下, 如何计算观察序列出现的概率$P(O|\lambda)$. 这个问题相对简单.</p>
<p>​    <strong>*</strong> 预测/解码. 已知模型参数$\lambda$和观察序列$O$的情况下, 求最有可能出现的隐藏状态序列, 会用到维特比算法, 要稍微难一些.</p>
<p>​    <strong>*</strong> 模型参数学习问题. 这个问题如果给定隐藏状态序列, 那么会非常简单, 直接统计就可以得到$\lambda$. 但是如果只给出观察序列$O$, 估计$\lambda$, 使得$P(O|\lambda)$最大, 就比较复杂了, 需要用到EM算法.</p>
<h1 id="估计观察序列概率"><a href="#估计观察序列概率" class="headerlink" title="估计观察序列概率"></a>估计观察序列概率</h1><p>假设现在已经知道了HMM的参数$\lambda$, 观测序列$O$, 求解$P(O|\lambda)$.</p>
<p>这个问题是比较简单的, 首先从直观的暴力法的角度来看. 如果能够列举出所有可能的长度为$T$的隐藏序列$H=\{h_1,h_2,\dots,h_T\}$, 那么对于每个可能的隐藏序列, 可以得到联合概率分布$P(O,H|\lambda)$, 这样就可以通过对所有可能求和, 得到边缘分布$P(O|\lambda)$:</p>
<script type="math/tex; mode=display">
P(O,H|\lambda)=P(H|\lambda)P(O|H,\lambda) \\
P(O|\lambda)=\sum_IP(O,H|\lambda)</script><p>对于暴力法来说, 其时间复杂度取决于序列长度$T$和隐藏状态数$N$, 为$O(TN^T)$.</p>
<p>OK, 现在有了暴力法, 那么接下来就只差简答的优化了ヽ(✿ﾟ▽ﾟ)ノ</p>
<p>优化方法仍然是属于动态规划方法(诶为什么说又), 叫做前向法. 有前向法就有后向法, 不过两者原理类似.</p>
<p>动态规划算法通常来说有几个要点:</p>
<ul>
<li>定义好子问题.</li>
<li>找到递推公式.</li>
<li>有一个初始解.</li>
</ul>
<p>那么在这里, 我们要求$P(O|\lambda)$, 不妨定义一个前向概率:</p>
<script type="math/tex; mode=display">
\alpha_t(i)=P(o_1,o_2,\dots,o_t,h_t=i|\lambda)</script><p>表示在$t$时隐藏状态为$i$, 同时观测序列为$O$的联合概率.</p>
<p>在$t=1$时, $\alpha_{1}(i)=A_{start\to i}\times B_{i\to o_1}$.</p>
<p>在$t&gt;1$时, $\alpha_{t}(j)=(\sum\limits_{i=1}^N \alpha_{t-1}(i) A_{i\to j})\times B_{j\to o_1}$. 这一步递推是核心, 即每一时刻的前向概率, 可以通过前一个时刻所有隐藏状态的前向概率求和得到.</p>
<p>在$t=T$时, 得到$\alpha_T(i)$, 而想要求解的$P(O|\lambda)=\sum_i\alpha_T(i)$</p>
<p>利用前向法估计观察序列的概率, 时间复杂度为$O(TN^2)$.</p>
<p>类似的, 定义后向概率:</p>
<script type="math/tex; mode=display">
\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T| h_t =i , \lambda)</script><p>对应的递推公式为:</p>
<script type="math/tex; mode=display">
\beta_{t}(i) = \sum\limits_{j=1}^{N}A_{i\to j}\times B_{j\to o_{t+1}}\times\beta_{t+1}(j)</script><p>基于上面两个前向与后向概率, 可以进一步得到下面几个概率公式, 它们将在HMM使用EM学习参数时发挥作用.</p>
<ul>
<li><p>给定参数$\lambda$和观察序列$O$, $h_t=i$的概率:</p>
<script type="math/tex; mode=display">
\gamma_t(i) = P(h_t = i | O,\lambda) = \frac{P(h_t = i ,O|\lambda)}{P(O|\lambda)}</script><p>由前向后向概率可得:</p>
<script type="math/tex; mode=display">
P(h_t = i ,O|\lambda) = \alpha_t(i)\beta_t(i)</script><p>所以:</p>
<script type="math/tex; mode=display">
\gamma_t(i) = \frac{ \alpha_t(i)\beta_t(i)}{\sum\limits_{j=1}^N \alpha_t(j)\beta_t(j)}</script></li>
<li><p>给定参数$\lambda$和观察序列$O$, $h_t=i,h_{t+1}=j$的概率:</p>
<script type="math/tex; mode=display">
\xi_t(i,j) = P(h_t = i, h_{t+1}=j | O,\lambda) = \frac{ P(h_t = i, h_{t+1}=j , O|\lambda)}{P(O|\lambda)}</script><p>由前向后向概率可得:</p>
<script type="math/tex; mode=display">
P(h_t = i, h_{t+1}=j , O|\lambda) = \alpha_t(i)A_{i\to j}B_{j\to O_{t+1}}\beta_{t+1}(j)</script><p>所以:</p>
<script type="math/tex; mode=display">
\xi_t(i,j) = \frac{\alpha_t(i)A_{i\to j}B_{j\to O_{t+1}}\beta_{t+1}(j)}{\sum\limits_{k=1}^N\sum\limits_{l=1}^N\alpha_t(k)A_{k\to l}B_{l\to O_{t+1}}\beta_{t+1}(l)}</script></li>
</ul>
<h1 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h1><p>解码, 或者预测, 指的是已知模型参数$\lambda$和观察序列$O$的情况下, 求最有可能出现的隐藏状态序列.</p>
<p>使用与分词那里类似的维特比算法, 找到合适的子问题, 以及递推关系进行逐步求解.</p>
<p>定义一个函数$\delta_t(h)$, 表示在$t$时状态节点为$i$的最大路径(概率):</p>
<script type="math/tex; mode=display">
\delta_t(h)=\max\limits_{h_1,h_2,\dots,h_{t-1}}P(o_1,o_2,\dots, o_t,h_1,h_2,\dots,h_{t-1},h_t=h|\lambda)</script><p>其中$h\in\{1,2,\dots,N\}$.</p>
<p>对应的递推表达式为:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\delta_{t+1}(h)&=\max\limits_{h_1,h_2,\dots,h_{t}}P(o_1,o_2,\dots, o_{t+1},h_1,h_2,\dots,h_{t},h_{t+1}=h|\lambda) \\
&=\max\limits_{1\le i\le N}(\delta_{t}(i)\times A_{i\to h})B_{h\to o_{t+1}}
\end{aligned}</script><p>有了上面的递推表达式, 可以从第一个状态节点$\delta_{1}(h)=A_{start\to h}B_{h\to o_{1}}$逐步往后计算, 同时需要记录下每个时刻下每个状态的上一个状态, 即路径.</p>
<p>在计算到$\delta_{T}(h)$时, 在$h\in\{1,2,\dots,N\}$中找到最大的状态, 其对应的路径, 既是需要求解的隐藏状态序列$H$.</p>
<h1 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h1><p>在模型参数估计时, 如果给定隐藏状态序列, 那么会非常简单, 直接统计就可以得到$\lambda$. 但是如果只给出观察序列$O$, 估计$\lambda$, 使得$P(O|\lambda)$最大, 就比较复杂了, 需要用到EM算法</p>
<h2 id="直接统计频次"><a href="#直接统计频次" class="headerlink" title="直接统计频次"></a>直接统计频次</h2><p>在一些情况下, 比如词性标注, 通常会有供学习的语料, 这些语料是已经标注好的, 即同时提供了观测序列$O$和状态序列$H$, 此时估计参数矩阵$A$和$B$的方式, 可以采用直接统计频次.</p>
<p>对于转移矩阵$A$来说:</p>
<script type="math/tex; mode=display">
A_{i\to i'}=\frac{count(i\to i')}{count(i)}</script><p>对于发射矩阵$B$来说:</p>
<script type="math/tex; mode=display">
B_{i\to j}=\frac{count(i\to j)}{count(i)}</script><p>没错, 就是这么简单.</p>
<h2 id="利用EM算法"><a href="#利用EM算法" class="headerlink" title="利用EM算法"></a>利用EM算法</h2><p>如果对EM算法不太了解的同学, 可以在我的博客的搜索页中, 查找一下”EM算法”的关键词, 即可看到专门对EM算法的介绍.</p>
<p>那么这里假设已经对EM算法流程熟悉了, 直接开搞.</p>
<p>按照EM算法, 需要分两步, 在E步的时候求出联合分布$P(O,H|\lambda)$基于条件概率$P(H|O;\lambda’)$的期望, 其中$\lambda’$为当前的模型参数; 然后在M步利用MLE最大化这个期望, 得到更新的模型参数$\lambda$, 作为下一轮迭代时的$\lambda’$, 直到最终收敛.</p>
<p>假设我们的训练数据为$\{(O_1, H_1), (O_2, H_2), …(O_D, H_D)\}$, 其中任意一个观测序列为$O_d = \{o_1^{(d)}, o_2^{(d)},\dots,o_T^{(d)}\}$, 其对应的隐藏序列为$H_d = \{h_1^{(d)}, h_2^{(d)},\dots,h_T^{(d)}\}$.</p>
<p>联合分布表达式为:</p>
<script type="math/tex; mode=display">
P(O,H|\lambda)=\prod_{d=1}^D (A_{start\to h_1^{(d)}}B_{h_1^{(d)}\to o_1^{(d)}})\times\cdots\times(A_{h_{T-1}^{(d)}\to h_T^{(d)}}B_{h_T^{(d)}\to o_T^{(d)}})</script><p>在E步的期望表达式为:</p>
<script type="math/tex; mode=display">
L(\lambda, \lambda') = \sum\limits_{
H}P(H|O,\lambda')\log P(O,H|\lambda)</script><p>在M步极大化上式, 由于$P(H|O,\lambda’) = P(H,O|\lambda’)/P(O|\lambda’)$, 且$P(O|\lambda’)$是常数, 因此要极大化的式子等价于:</p>
<script type="math/tex; mode=display">
L(\lambda, \lambda') = \sum\limits_{
H}P(O, H|\lambda')\log P(O,H|\lambda)</script><p>将$P(O,H|\lambda)$带入, 可得:</p>
<script type="math/tex; mode=display">
\lambda'=arg\max_\lambda \sum_{d=1}^D\sum\limits_{
H}P(O, H|\lambda')(\sum_{t=1}^{T}\log A_{h_{T-1}^{(d)}\to h_T^{(d)}}+\sum_{t=1}^{T}\log B_{h_T^{(d)}\to o_T^{(d)}})</script><p>首先求解$A$, 此时式子可整理为:</p>
<script type="math/tex; mode=display">
\sum_{d=1}^D\sum\limits_{
H}\sum_{t=1}^{T}P(O, H|\lambda')\log A_{h_{t-1}^{(d)}\to h_t^{(d)}}=\sum_{d=1}^D\sum_{i=1}^N\sum_{j=1}^N\sum_{t=1}^{T}P(O, h_{t-1}^{(d)}=i,h_{t}^{(d)}=j|\lambda')\log A_{i\to j}</script><p>同时由于$A_{i\to j}$满足约束条件$\sum\limits_{j}A_{i\to j}=1$, 所以利用拉格朗日乘子法, 得到拉格朗日函数, 对$A_{i\to j}$求偏导, 并令其等于0, 可得到:</p>
<script type="math/tex; mode=display">
A_{i\to j}=\frac{\sum\limits_{d=1}^D\sum\limits_{t=1}^{T}P(O^{(d)}, h_{t-1}^{(d)} = i, h_{t}^{(d)} = j|\lambda')}{\sum\limits_{d=1}^D\sum\limits_{t=1}^{T}P(O^{(d)}, h_{t-1}^{(d)} = i|\lambda')} \tag{1}</script><p>然后求解$B$, 与求解$A$一样:</p>
<script type="math/tex; mode=display">
\sum_{d=1}^D\sum\limits_{
H}\sum_{t=1}^{T}P(O, H|\lambda')\log B_{h_{t}^{(d)}\to o_t^{(d)}}=\sum_{d=1}^D\sum_{i=1}^N\sum_{t=1}^{T}P(O, h_{t}^{(d)}=i|\lambda')\log B_{i\to o_t^{(d)}}</script><p>并且$B_{i\to j}$满足$\sum\limits_{j}B_{i\to j}=1$, 同样使用拉格朗日乘子法可得:</p>
<script type="math/tex; mode=display">
B_{i\to j}=\frac{\sum\limits_{d=1}^D\sum\limits_{t=1}^{T}P(O^{(d)}, h_{t}^{(d)} = i|\lambda')I(o_t^{(d)}=j)}{\sum\limits_{d=1}^D\sum\limits_{t=1}^{T}P(O^{(d)}, h_{t}^{(d)} = i|\lambda')} \tag{2}</script><p>其中$I(o_t^{(d)}=j)$当且仅当$o_t^{(d)}=j$时为1, 否则为0.</p>
<p>上面式$(1)$和式$(2)$即为最后用于迭代的公式, 其中涉及到的运算在前面几小节中也有涉及到, 包括$\gamma_t(i)$与$\xi_t(i,j)$.</p>
<h1 id="HMM的局限性"><a href="#HMM的局限性" class="headerlink" title="HMM的局限性"></a>HMM的局限性</h1><p>那么, HMM有没有啥缺点呢, 或者说HMM有没有啥局限性呢?</p>
<p>当然是有的, 从HMM的模型结构与假设出发, 就比较容易能够看出其局限性.</p>
<p>首先是状态序列的马尔科夫性, 当前节点仅依赖过去节点, 这某种意义上类似于Bigram, 属于考虑了序列信息, 但只包含了局部信息.</p>
<p>然后就是观测序列, 每个时刻的观测序列仅依赖于当前状态序列, 这可能也是有一些问题的, 为什么不能依赖于当前节点之前或者之后的节点呢?</p>
<p>以上两个不足, 可能会带来一些问题. 例如, 通过现有的参数$\lambda$, 得到状态$a$到状态$b$的转移概率$P_{a\to b}$较大, 同时状态$b$到观测$c$的发射概率$P_{b\to c}$也较大, 那么通过HMM就可以推断$P_{a\to b\to c}$的概率较大. 但是, 实际上在真实数据中$P_{a\to b\to c}$概率可能很小, 只是因为HMM局部地学习了$P_{a\to b}$和$P_{b\to c}$, 导致出现了这样的错误.</p>
<p>针对这样的问题, 条件随机场CRF等模型做出来改进.</p>
<p>尽管如此, HMM仍然在不少任务中可以使用, 特别是在训练数据不多的时候.</p>
<h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><p>如果要体验HMM模型的使用, 可以尝试一个叫hmmlearn的Python包, 从名字就可以看出来, 与sklearn的API格式是比较类似的, 所以使用起来也比较简单.</p>
<p>在hmmlearn中, 实现了三种HMM模型, 其中包括:</p>
<p>​    <strong>*</strong> MultinomialHMM, 就是上面讲到的HMM模型, 其观察序列是离散的.</p>
<p>​    <strong>*</strong> GaussianHMM, 其观察序列是连续的, 服从高斯分布, 此时状态序列与观察序列之间的关系不能再使用发射矩阵$B$描述, 而使用均值与协方差描述.</p>
<p>​    <strong>*</strong> GMMHMM, 其观察序列服从混合高斯分布, 相对复杂一些, 一般使用GaussianHMM即可.</p>
<p>这里主要对MultinomialHMM的解码, 生成, 训练做一个展示, GaussianHMM与GMMHMM的使用是类似的.</p>
<p>对于MultinomialHMM模型, 使用比较简单, <code>startprob_</code>参数表示状态序列初始分布$A_{start}$, <code>transmat_</code>表示状态转移矩阵$A$, <code>emissionprob_</code>表示发射矩阵$B$.</p>
<p>这里假设有两枚硬币, 每次随机选取一枚(初始分布为$[0.5, 0.5]$), 硬币1的则转移概率为$[0.7, 0.3]$, 硬币2的转移概率为$[0.5, 0.5]$, 硬币1翻正反面概率为$[0.5,0.5]$, 硬币2翻正反面概率为$[0.8,0.2]$.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> hmmlearn <span class="keyword">import</span> hmm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置观察与状态的离散值</span></span><br><span class="line">states = [<span class="string">'硬币1'</span>, <span class="string">'硬币2'</span>]</span><br><span class="line">n_states = len(states)</span><br><span class="line"></span><br><span class="line">observations = [<span class="string">'正面'</span>, <span class="string">'反面'</span>]</span><br><span class="line">n_observations = len(observations)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置初始分布, 转移矩阵, 发射矩阵</span></span><br><span class="line">init_prob = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">A = np.array([[<span class="number">0.7</span>, <span class="number">0.3</span>],</span><br><span class="line">              [<span class="number">0.3</span>, <span class="number">0.7</span>]])</span><br><span class="line">B = np.array([[<span class="number">0.2</span>, <span class="number">0.8</span>],</span><br><span class="line">              [<span class="number">0.8</span>, <span class="number">0.2</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造模型</span></span><br><span class="line">model = hmm.MultinomialHMM(n_components=n_states)</span><br><span class="line">model.startprob_ = init_prob</span><br><span class="line">model.transmat_ = A</span><br><span class="line">model.emissionprob_ = B</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算观察序列概率</span></span><br><span class="line">seen_list = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]).reshape((<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">np.exp(model.score(seen_list))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.026785999999999994</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解码 decode或predict方法都可以</span></span><br><span class="line">log_prob_list, decode_list = model.decode(seen_list, algorithm=<span class="string">"viterbi"</span>)</span><br><span class="line">print(<span class="string">'观察序列: %s'</span> % <span class="string">', '</span>.join(map(<span class="keyword">lambda</span> x: observations[x[<span class="number">0</span>]], seen_list)))</span><br><span class="line">print(<span class="string">'状态序列: %s'</span> % <span class="string">', '</span>.join(map(<span class="keyword">lambda</span> x: states[x], decode_list)))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">观察序列: 正面, 正面, 反面, 反面, 正面</span><br><span class="line">状态序列: 硬币2, 硬币2, 硬币1, 硬币1, 硬币2</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用上面的模型, 生成观察序列和状态序列</span></span><br><span class="line"><span class="comment"># 每次生成不同的长度, 并记录每次的序列长度, 用于接下来的训练</span></span><br><span class="line">np.random.seed(<span class="number">7</span>)</span><br><span class="line">seen_list = <span class="literal">None</span></span><br><span class="line">len_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    tmp_len = np.random.randint(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">    tmp_seen_list, _ = model.sample(tmp_len)</span><br><span class="line">    len_list.append(tmp_len)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        seen_list = tmp_seen_list</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        seen_list = np.concatenate([seen_list, tmp_seen_list])</span><br><span class="line">seen_list[: <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">array([[0],</span><br><span class="line">       [1],</span><br><span class="line">       [0],</span><br><span class="line">       [1],</span><br><span class="line">       [1]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练</span></span><br><span class="line">model = hmm.MultinomialHMM(n_components=n_states, random_state=<span class="number">7</span>, n_iter=<span class="number">1000</span>)</span><br><span class="line">model.fit(seen_list, lengths=len_list)</span><br><span class="line">print(model.startprob_)</span><br><span class="line">print(model.transmat_)</span><br><span class="line">print(model.emissionprob_)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[0.44676585 0.55323415]</span><br><span class="line">[[0.65659885 0.34340115]</span><br><span class="line"> [0.2695147  0.7304853 ]]</span><br><span class="line">[[0.14879228 0.85120772]</span><br><span class="line"> [0.77509473 0.22490527]]</span><br></pre></td></tr></table></figure>
<p>对比输出结果和一开始的参数设置, 发现是非常接近的, 奥利给!</p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/EM算法/" rel="tag"># EM算法</a>
          
            <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
          
            <a href="/tags/HMM/" rel="tag"># HMM</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/08/16/自然语言处理/分词/" rel="next" title="分词">
                <i class="fa fa-chevron-left"></i> 分词
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/08/16/自然语言处理/条件随机场CRF-一/" rel="prev" title="条件随机场CRF(一)">
                条件随机场CRF(一) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">月小白</p>
  <div class="site-description motion-element" itemprop="description">这是一家有爱的小店</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">96</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    

    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>













          
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#HMM介绍"><span class="nav-number">1.</span> <span class="nav-text">HMM介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#估计观察序列概率"><span class="nav-number">2.</span> <span class="nav-text">估计观察序列概率</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#解码"><span class="nav-number">3.</span> <span class="nav-text">解码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型参数估计"><span class="nav-number">4.</span> <span class="nav-text">模型参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#直接统计频次"><span class="nav-number">4.1.</span> <span class="nav-text">直接统计频次</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#利用EM算法"><span class="nav-number">4.2.</span> <span class="nav-text">利用EM算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HMM的局限性"><span class="nav-number">5.</span> <span class="nav-text">HMM的局限性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代码示例"><span class="nav-number">6.</span> <span class="nav-text">代码示例</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">月小白</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>



        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  















  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  


  


  




  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  




  



<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>


  

  

  


  

</body>
</html>
